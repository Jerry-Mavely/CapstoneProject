{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e32f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import subprocess\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Install pgeocode for geographic distance calculation\n",
    "try:\n",
    "    import pgeocode\n",
    "except ImportError:\n",
    "    print(\"Installing pgeocode...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pgeocode\"], check=True)\n",
    "    import pgeocode\n",
    "\n",
    "try:\n",
    "    from ethnicolr import census_ln\n",
    "except ImportError:\n",
    "    print(\"Installing ethnicolr...\")\n",
    "    # Note: ethnicolr requires TensorFlow. This installation might take a moment.\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"ethnicolr\"], check=True)\n",
    "    from ethnicolr import census_ln\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import joblib\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8c01adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes loaded successfully.\n",
      "Patient DF shape: (100000, 16)\n",
      "Encounter DF shape: (200000, 17)\n",
      "Provider DF shape: (5000, 19)\n",
      "Hospital DF shape: (200, 14)\n"
     ]
    }
   ],
   "source": [
    "#file locations\n",
    "parquet_file_paths={\n",
    "    \"patient\": r\"Client_Data_files\\Parquets\\synthetic_patients.parquet\",\n",
    "    \"encounter\": r\"Client_Data_files\\Parquets\\synthetic_encounters.parquet\",\n",
    "    \"hospitals\": r\"Client_Data_files\\Parquets\\synthetic_hospitals.parquet\",\n",
    "    \"provider\": r\"Client_Data_files\\Parquets\\synthetic_providers.parquet\",    \n",
    "}\n",
    "\n",
    "# Reading the parquet files\n",
    "patient_df = pd.read_parquet(parquet_file_paths['patient'])\n",
    "encounter_df = pd.read_parquet(parquet_file_paths['encounter'])\n",
    "hospital_df = pd.read_parquet(parquet_file_paths['hospitals'])\n",
    "provider_df = pd.read_parquet(parquet_file_paths['provider'])\n",
    "\n",
    "print(\"Dataframes loaded successfully.\")\n",
    "print(f\"Patient DF shape: {patient_df.shape}\")\n",
    "print(f\"Encounter DF shape: {encounter_df.shape}\")\n",
    "print(f\"Provider DF shape: {provider_df.shape}\")\n",
    "print(f\"Hospital DF shape: {hospital_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "208db927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: patient\n",
      "Shape: (100000, 16)\n",
      "Columns: ['patient_id', 'first_name', 'last_name', 'date_of_birth', 'gender', 'race', 'ethnicity', 'primary_language', 'zip_code', 'insurance_type', 'household_income', 'education_level', 'age', 'cultural_background', 'preferred_provider_language', 'cultural_preferences']\n",
      "\n",
      "Dataframe: encounter\n",
      "Shape: (200000, 17)\n",
      "Columns: ['encounter_id', 'patient_id', 'provider_id', 'encounter_date', 'encounter_type', 'primary_diagnosis', 'length_of_stay', 'total_cost', 'cultural_background', 'primary_language', 'languages_spoken', 'cultural_competency_rating', 'cultural_match_score', 'language_match', 'patient_satisfaction', 'treatment_adherence', 'return_visit_30_days']\n",
      "\n",
      "Dataframe: hospitals\n",
      "Shape: (200, 14)\n",
      "Columns: ['hospital_id', 'hospital_name', 'hospital_type', 'zip_code', 'bed_count', 'teaching_hospital', 'trauma_center', 'language_services_available', 'cultural_competency_program', 'interpreter_services_24_7', 'community_health_programs', 'overall_rating', 'patient_safety_rating', 'readmission_rate']\n",
      "Column 'community_health_programs' has 121 missing values.\n",
      "\n",
      "Dataframe: provider\n",
      "Shape: (5000, 19)\n",
      "Columns: ['provider_id', 'npi_number', 'first_name', 'last_name', 'specialty', 'practice_zip_code', 'years_experience', 'medical_school_country', 'board_certified', 'languages_spoken', 'interpreter_services', 'cultural_certifications', 'minority_health_experience', 'community_involvement', 'patient_satisfaction_score', 'communication_rating', 'cultural_competency_rating', 'hospital_affiliation', 'accepts_new_patients']\n",
      "Column 'cultural_certifications' has 4056 missing values.\n",
      "Column 'community_involvement' has 4270 missing values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a data map for easy access\n",
    "data_map={\n",
    "    \"patient\": patient_df,\n",
    "    \"encounter\": encounter_df,\n",
    "    \"hospitals\": hospital_df,\n",
    "    \"provider\": provider_df\n",
    "}\n",
    "\n",
    "for key, df in data_map.items():\n",
    "    print(f\"Dataframe: {key}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")    \n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            print(f\"Column '{col}' has {df[col].isna().sum()} missing values.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2fcfc610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 12:40:23,769 - INFO - Preserving 12965 duplicate rows based on column 'last_name'\n",
      "2025-09-29 12:40:23,769 - INFO - Data filtering summary: 12997 → 12997 rows (kept 100.0%)\n",
      "2025-09-29 12:40:23,800 - INFO - Merging demographic data for 12997 records...\n",
      "2025-09-29 12:40:23,954 - INFO - Matched 12997 of 12997 rows (100.0%)\n",
      "2025-09-29 12:40:23,954 - INFO - Added columns: pct2prace, pctaian, pctapi, pctblack, pcthispanic, pctwhite\n"
     ]
    }
   ],
   "source": [
    "patient_df_temp=pd.DataFrame()\n",
    "patient_df_temp=patient_df[patient_df['race']=='Hispanic or Latino'][['patient_id','first_name','last_name','race','ethnicity']].copy()\n",
    "patient_race_pred=census_ln(patient_df_temp, 'last_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a5dc3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_mapping={\n",
    "    'white': 'White',\n",
    "    'black': 'Black or African American',\n",
    "    'api': 'Asian',    \n",
    "    'aian': 'Native American',\n",
    "    '2prace': 'Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55a95de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_cols=['pctwhite','pctblack','pctapi','pctaian','pct2prace']\n",
    "patient_race_pred['derived_race'] = patient_race_pred[race_cols].idxmax(axis=1).str.replace('pct', '').map(race_mapping)\n",
    "\n",
    "# Create a mapping from patient_id to derived_race\n",
    "id_to_derived_race = dict(zip(patient_race_pred['patient_id'], patient_race_pred['derived_race']))\n",
    "\n",
    "# Update the race column only for Hispanic or Latino patients\n",
    "patient_df.loc[patient_df['race'] == 'Hispanic or Latino', 'race'] = \\\n",
    "    patient_df.loc[patient_df['race'] == 'Hispanic or Latino', 'patient_id'].map(id_to_derived_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1d3dc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 12:40:24,051 - INFO - Preserving 4968 duplicate rows based on column 'last_name'\n",
      "2025-09-29 12:40:24,051 - INFO - Data filtering summary: 5000 → 5000 rows (kept 100.0%)\n",
      "2025-09-29 12:40:24,065 - INFO - Merging demographic data for 5000 records...\n",
      "2025-09-29 12:40:24,116 - INFO - Matched 5000 of 5000 rows (100.0%)\n",
      "2025-09-29 12:40:24,116 - INFO - Added columns: pct2prace, pctaian, pctapi, pctblack, pcthispanic, pctwhite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving race for providers from last names...\n",
      "Provider race derivation complete.\n",
      "Deriving ethnicity for providers from race predictions...\n",
      "Provider ethnicity derivation complete.\n"
     ]
    }
   ],
   "source": [
    "provider_race_predictions = census_ln(provider_df, 'last_name')\n",
    "\n",
    "# Derive race for the provider_df as it is missing from the source data\n",
    "print(\"Deriving race for providers from last names...\")\n",
    "race_cols = ['pctwhite','pctblack','pctapi','pctaian','pct2prace']\n",
    "provider_df['provider_race'] = provider_race_predictions[race_cols].idxmax(axis=1).str.replace('pct', '').map(race_mapping)\n",
    "print(\"Provider race derivation complete.\")\n",
    "\n",
    "# Deriving provider ethnicity from the race_predictions\n",
    "print(\"Deriving ethnicity for providers from race predictions...\")\n",
    "provider_df['provider_ethnicity'] = provider_race_predictions['pcthispanic'].apply(lambda x: 'Hispanic or Latino' if float(x) >= 50 else 'Not Hispanic or Latino')\n",
    "print(\"Provider ethnicity derivation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fcf27b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: patient\n",
      "Shape: (100000, 16)\n",
      "Columns: ['patient_id', 'first_name', 'last_name', 'date_of_birth', 'gender', 'race', 'ethnicity', 'primary_language', 'zip_code', 'insurance_type', 'household_income', 'education_level', 'age', 'cultural_background', 'preferred_provider_language', 'cultural_preferences']\n",
      "\n",
      "Dataframe: encounter\n",
      "Shape: (200000, 17)\n",
      "Columns: ['encounter_id', 'patient_id', 'provider_id', 'encounter_date', 'encounter_type', 'primary_diagnosis', 'length_of_stay', 'total_cost', 'cultural_background', 'primary_language', 'languages_spoken', 'cultural_competency_rating', 'cultural_match_score', 'language_match', 'patient_satisfaction', 'treatment_adherence', 'return_visit_30_days']\n",
      "\n",
      "Dataframe: hospitals\n",
      "Shape: (200, 14)\n",
      "Columns: ['hospital_id', 'hospital_name', 'hospital_type', 'zip_code', 'bed_count', 'teaching_hospital', 'trauma_center', 'language_services_available', 'cultural_competency_program', 'interpreter_services_24_7', 'community_health_programs', 'overall_rating', 'patient_safety_rating', 'readmission_rate']\n",
      "Column 'community_health_programs' has 121 missing values.\n",
      "\n",
      "Dataframe: provider\n",
      "Shape: (5000, 21)\n",
      "Columns: ['provider_id', 'npi_number', 'first_name', 'last_name', 'specialty', 'practice_zip_code', 'years_experience', 'medical_school_country', 'board_certified', 'languages_spoken', 'interpreter_services', 'cultural_certifications', 'minority_health_experience', 'community_involvement', 'patient_satisfaction_score', 'communication_rating', 'cultural_competency_rating', 'hospital_affiliation', 'accepts_new_patients', 'provider_race', 'provider_ethnicity']\n",
      "Column 'cultural_certifications' has 4056 missing values.\n",
      "Column 'community_involvement' has 4270 missing values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, df in data_map.items():\n",
    "    print(f\"Dataframe: {key}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")    \n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            print(f\"Column '{col}' has {df[col].isna().sum()} missing values.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381511fe",
   "metadata": {},
   "source": [
    "### Step 2: Feature Engineering\n",
    "\n",
    "Here, we merge the datasets and create the features our model will learn from. This includes cultural matches, language matches, and geographic distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "564990c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master DataFrame created with shape: (200000, 66)\n"
     ]
    }
   ],
   "source": [
    "# Merge all data into a single master DataFrame for training\n",
    "master_df = pd.merge(encounter_df, patient_df, on='patient_id',suffixes=('', '_pat'))\n",
    "master_df = pd.merge(master_df, provider_df, on='provider_id',suffixes=('', '_prov'))\n",
    "master_df = pd.merge(master_df, hospital_df, left_on='hospital_affiliation', right_on='hospital_id',suffixes=('', '_hosp'))\n",
    "\n",
    "print(\"Master DataFrame created with shape:\", master_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd8e7604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encounter_id', 'patient_id', 'provider_id', 'encounter_date',\n",
       "       'encounter_type', 'primary_diagnosis', 'length_of_stay', 'total_cost',\n",
       "       'cultural_background', 'primary_language', 'languages_spoken',\n",
       "       'cultural_competency_rating', 'cultural_match_score', 'language_match',\n",
       "       'patient_satisfaction', 'treatment_adherence', 'return_visit_30_days',\n",
       "       'first_name', 'last_name', 'date_of_birth', 'gender', 'race',\n",
       "       'ethnicity', 'primary_language_pat', 'zip_code', 'insurance_type',\n",
       "       'household_income', 'education_level', 'age', 'cultural_background_pat',\n",
       "       'preferred_provider_language', 'cultural_preferences', 'npi_number',\n",
       "       'first_name_prov', 'last_name_prov', 'specialty', 'practice_zip_code',\n",
       "       'years_experience', 'medical_school_country', 'board_certified',\n",
       "       'languages_spoken_prov', 'interpreter_services',\n",
       "       'cultural_certifications', 'minority_health_experience',\n",
       "       'community_involvement', 'patient_satisfaction_score',\n",
       "       'communication_rating', 'cultural_competency_rating_prov',\n",
       "       'hospital_affiliation', 'accepts_new_patients', 'provider_race',\n",
       "       'provider_ethnicity', 'hospital_id', 'hospital_name', 'hospital_type',\n",
       "       'zip_code_hosp', 'bed_count', 'teaching_hospital', 'trauma_center',\n",
       "       'language_services_available', 'cultural_competency_program',\n",
       "       'interpreter_services_24_7', 'community_health_programs',\n",
       "       'overall_rating', 'patient_safety_rating', 'readmission_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd9d9485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerry\\AppData\\Local\\Temp\\ipykernel_21188\\1441209.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df['distance_km'].fillna(mean_dist_by_specialty, inplace=True)\n",
      "C:\\Users\\jerry\\AppData\\Local\\Temp\\ipykernel_21188\\1441209.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df['distance_km'].fillna(master_df['distance_km'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Engineer the Match Features ---\n",
    "\n",
    "# Stateless Cultural Features\n",
    "master_df['race_match'] = (master_df['race'] == master_df['provider_race']).astype(int)\n",
    "master_df['ethnicity_match'] = (master_df['ethnicity'] == master_df['provider_ethnicity']).astype(int)\n",
    "master_df['language_match'] = (master_df['language_match'] == True).astype(int)\n",
    "\n",
    "\n",
    "master_df['encounter_date'] = pd.to_datetime(master_df['encounter_date'])\n",
    "\n",
    "# Geographic Feature\n",
    "dist = pgeocode.GeoDistance('US') # Assuming US zip codes\n",
    "# Calculate distance between patient and provider zip codes\n",
    "master_df['distance_km'] = dist.query_postal_code(\n",
    "    master_df['zip_code'].astype(str).tolist(), \n",
    "    master_df['zip_code_hosp'].astype(str).tolist()\n",
    ")\n",
    "# Calculate the mean distance for each provider specialty\n",
    "# The .transform('mean') creates a Series with the same index as master_df,\n",
    "mean_dist_by_specialty = master_df.groupby('specialty')['distance_km'].transform('mean')\n",
    "\n",
    "# Now, fill the missing distances using these specialty-specific averages\n",
    "master_df['distance_km'].fillna(mean_dist_by_specialty, inplace=True)\n",
    "\n",
    "# If any specialties had NO valid distances, there might still be NaNs.\n",
    "# Fill any remaining with the overall mean as a final fallback.\n",
    "master_df['distance_km'].fillna(master_df['distance_km'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Create a function to apply the transformations consistently\n",
    "def create_features(df, avg_adherence, min_dist, max_dist):\n",
    "    df_eng = df.copy() # Work on a copy to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Historical Adherence\n",
    "    df_sorted = df_eng.sort_values(by=['patient_id', 'encounter_date'])\n",
    "    df_sorted['shifted_adherence'] = df_sorted.groupby('patient_id')['treatment_adherence'].shift(1)\n",
    "    df_sorted['treatment_sum'] = df_sorted.groupby('patient_id')['shifted_adherence'].cumsum().fillna(0)\n",
    "    df_sorted['treatment_count'] = df_sorted.groupby('patient_id').cumcount()\n",
    "    df_sorted['historical_avg_adherence'] = np.where(\n",
    "        df_sorted['treatment_count'] > 0,\n",
    "        df_sorted['treatment_sum'] / df_sorted['treatment_count'],\n",
    "        avg_adherence # Use the learned average for cold starts\n",
    "    )\n",
    "    df_eng = df_sorted.copy()\n",
    "    \n",
    "    # Proximity Score\n",
    "    df_eng['proximity_score'] = 1 - ((df_eng['distance_km'] - min_dist) / (max_dist - min_dist))\n",
    "    df_eng['proximity_score'] = df_eng['proximity_score'].clip(0, 1)\n",
    "    \n",
    "    return df_eng\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b75b5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 1. First, calculate the min and max distances from data\n",
    "# # min_distance = master_df['distance_km'].min()\n",
    "# # max_distance = master_df['distance_km'].max()\n",
    "\n",
    "# # # 2. Apply the scaling formula to create a score from 0 to 1\n",
    "# # # The formula is: 1 - ( (x - min) / (max - min) )\n",
    "\n",
    "# # master_df['proximity_score'] = 1 - (\n",
    "# #     (master_df['distance_km'] - min_distance) / (max_distance - min_distance)\n",
    "# # )\n",
    "\n",
    "# # master_df['encounter_date'] = pd.to_datetime(master_df['encounter_date'])\n",
    "# # df_sorted = master_df.sort_values(by=['patient_id', 'encounter_date'])\n",
    "\n",
    "# # average_adherence = df_sorted['treatment_adherence'].mean()\n",
    "\n",
    "# # df_sorted['shifted_adherence'] = df_sorted.groupby('patient_id')['treatment_adherence'].shift(1)\n",
    "\n",
    "# # # 2. Now, calculate the cumulative sum on this correctly shifted column.\n",
    "# # df_sorted['treatment_adherence_sum'] = df_sorted.groupby('patient_id')['shifted_adherence'].cumsum()\n",
    "# # df_sorted['treatment_adherence_sum'].fillna(0, inplace=True)\n",
    "\n",
    "# # df_sorted['treatment_adherence_count'] = df_sorted.groupby('patient_id').cumcount()\n",
    "\n",
    "# # df_sorted['historical_avg_adherence'] = np.where(\n",
    "# #     df_sorted['treatment_adherence_count'] > 0,                                        # The condition to check\n",
    "# #     df_sorted['treatment_adherence_sum'] / df_sorted['treatment_adherence_count'],     # The value if the condition is True\n",
    "# #     average_adherence                                                                # The value if the condition is False\n",
    "# # )\n",
    "\n",
    "\n",
    "# # # Add the new feature back to the original master_df\n",
    "# # master_df['historical_avg_adherence'] = df_sorted['historical_avg_adherence']\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"Feature engineering complete.\")\n",
    "# # master_df[['race_match', 'ethnicity_match', 'language_match', 'distance_km','proximity_score']].head()\n",
    "# print(master_df['proximity_score'].isna().sum())\n",
    "# master_df['proximity_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad339703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_df.to_csv('master_df_v1_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c06a3",
   "metadata": {},
   "source": [
    "### Step 3: Training and Testing the Model\n",
    "\n",
    "This is the core machine learning section. We split our data, train the model, and then test it on unseen data to validate its performance. The feature importances are the **learned weights**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "29dec8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cultural preferences found:  ['No Specific Preference' 'Culturally Similar Provider'\n",
      " 'Culturally Similar Provider; Same Language Provider'\n",
      " 'Same Language Provider']\n"
     ]
    }
   ],
   "source": [
    "Model_Name=\"RandomForestRegressor_PatientSatisfactionOnly\"\n",
    "Model_code='RFR_Pat_Sat'\n",
    "Model_Summary= \\\n",
    "\"\"\"This report details a Segmented Learning to Rank (LTR) system built to generate personalized doctor recommendations. \n",
    "The system utilizes machine learning to predict patient satisfaction.\n",
    "The core of the approach is its segmented architecture: instead of a single general model, a separate \"expert\" Random Forest model is trained \n",
    "for each patient's cultural_preference group. \n",
    "Each model is optimized through hyperparameter tuning to learn the unique importance of various features—including \n",
    "cultural fit, language match, and geographic proximity—for its specific audience. \n",
    "All models were rigorously validated on a held-out test set to ensure reliable and unbiased performance. \n",
    "\"\"\"\n",
    "\n",
    "# --- Training Section ---\n",
    "\n",
    "# 1. Normalize the columns to a 0-1 scale\n",
    "scaler = MinMaxScaler()\n",
    "master_df[['satisfaction_norm', 'adherence_norm']] = scaler.fit_transform(\n",
    "    master_df[['patient_satisfaction', 'treatment_adherence']]\n",
    ")\n",
    "\n",
    "# 2. Define weights and create the composite score\n",
    "adherence_weight = 0\n",
    "satisfaction_weight = 1\n",
    "master_df['success_score'] = (\n",
    "    master_df['adherence_norm'] * adherence_weight +\n",
    "    master_df['satisfaction_norm'] * satisfaction_weight\n",
    ")\n",
    "\n",
    "# Rename provider competency column to avoid conflict\n",
    "master_df.rename(columns={'cultural_competency_rating_y': 'cultural_competency_rating_prov'}, inplace=True)\n",
    "\n",
    "# Define the features to be used by the models\n",
    "features_stateless = [\n",
    "    'years_experience',\n",
    "    'cultural_competency_rating_prov',\n",
    "    'communication_rating',\n",
    "    'race_match',\n",
    "    'ethnicity_match',\n",
    "    'language_match',    \n",
    "    'interpreter_services_24_7',    \n",
    "]\n",
    "features_stateful = [\n",
    "    'historical_avg_adherence',\n",
    "    'proximity_score',  \n",
    "]\n",
    "\n",
    "features=features_stateless + features_stateful\n",
    "\n",
    "target = 'success_score'\n",
    "\n",
    "# Get the unique preference categories to loop through\n",
    "unique_preferences = master_df['cultural_preferences'].unique()\n",
    "print(\"Unique cultural preferences found: \", unique_preferences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dbc7e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for cultural preference: No Specific Preference (1/4)--------------------------------------\n",
      "Learning feature engineering parameters from the training set...\n",
      "training on features: ['years_experience', 'cultural_competency_rating_prov', 'communication_rating', 'race_match', 'ethnicity_match', 'language_match', 'interpreter_services_24_7', 'historical_avg_adherence', 'proximity_score']\n",
      "Training+Validation set size: 69151 samples\n",
      "Test set size: 17288 samples\n",
      "\n",
      "Starting random parameter search ...\n",
      "  > Running trial 50/50...\n",
      "Search complete after 50 trials. Analyzing results...\n",
      "\n",
      "--- Top 5 Hyperparameter Runs (based on lowest validation RMSE) ---\n",
      "                                               params  mean_rmse  mean_mae  \\\n",
      "20  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.166931  0.148256   \n",
      "49  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.166931  0.148256   \n",
      "34  {'n_estimators': 150, 'min_samples_leaf': 4, '...   0.166941  0.148261   \n",
      "26  {'n_estimators': 100, 'min_samples_leaf': 4, '...   0.166944  0.148262   \n",
      "1   {'n_estimators': 200, 'min_samples_leaf': 2, '...   0.166957  0.148287   \n",
      "\n",
      "     mean_r2  \n",
      "20 -0.001656  \n",
      "49 -0.001656  \n",
      "34 -0.001776  \n",
      "26 -0.001811  \n",
      "1  -0.001969  \n",
      "\n",
      "Best parameters found: {'n_estimators': 200, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "\n",
      "--- Final Evaluation on the Held-Out Test Set ---\n",
      "Test set size: 17288 encounters\n",
      "\n",
      "--- Final Model Validation Metrics ---\n",
      "Root Mean Squared Error (RMSE): 0.1668\n",
      "Mean Absolute Error (MAE):     0.1483\n",
      "R-squared (R²):                -0.0020\n",
      "\n",
      "--- Learned Feature Weights for this Segment ---\n",
      "proximity_score                    0.221530\n",
      "communication_rating               0.209755\n",
      "historical_avg_adherence           0.188600\n",
      "cultural_competency_rating_prov    0.186564\n",
      "years_experience                   0.132368\n",
      "interpreter_services_24_7          0.023554\n",
      "race_match                         0.019669\n",
      "ethnicity_match                    0.017960\n",
      "language_match                     0.000000\n",
      "dtype: float64\n",
      "\n",
      "--- Best model for 'No Specific Preference' trained and stored ----------------------------------------------------------------\n",
      "Training model for cultural preference: Culturally Similar Provider (2/4)--------------------------------------\n",
      "Learning feature engineering parameters from the training set...\n",
      "training on features: ['years_experience', 'cultural_competency_rating_prov', 'communication_rating', 'race_match', 'ethnicity_match', 'language_match', 'interpreter_services_24_7', 'historical_avg_adherence', 'proximity_score']\n",
      "Training+Validation set size: 55405 samples\n",
      "Test set size: 13852 samples\n",
      "\n",
      "Starting random parameter search ...\n",
      "  > Running trial 50/50...\n",
      "Search complete after 50 trials. Analyzing results...\n",
      "\n",
      "--- Top 5 Hyperparameter Runs (based on lowest validation RMSE) ---\n",
      "                                               params  mean_rmse  mean_mae  \\\n",
      "34  {'n_estimators': 150, 'min_samples_leaf': 4, '...   0.165863  0.147184   \n",
      "20  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.165869  0.147191   \n",
      "49  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.165869  0.147191   \n",
      "26  {'n_estimators': 100, 'min_samples_leaf': 4, '...   0.165878  0.147193   \n",
      "1   {'n_estimators': 200, 'min_samples_leaf': 2, '...   0.165886  0.147216   \n",
      "\n",
      "     mean_r2  \n",
      "34 -0.001579  \n",
      "20 -0.001644  \n",
      "49 -0.001644  \n",
      "26 -0.001759  \n",
      "1  -0.001849  \n",
      "\n",
      "Best parameters found: {'n_estimators': 150, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "\n",
      "--- Final Evaluation on the Held-Out Test Set ---\n",
      "Test set size: 13852 encounters\n",
      "\n",
      "--- Final Model Validation Metrics ---\n",
      "Root Mean Squared Error (RMSE): 0.1656\n",
      "Mean Absolute Error (MAE):     0.1465\n",
      "R-squared (R²):                -0.0017\n",
      "\n",
      "--- Learned Feature Weights for this Segment ---\n",
      "communication_rating               0.219586\n",
      "proximity_score                    0.203920\n",
      "cultural_competency_rating_prov    0.181965\n",
      "historical_avg_adherence           0.175841\n",
      "years_experience                   0.137031\n",
      "ethnicity_match                    0.028112\n",
      "race_match                         0.027680\n",
      "interpreter_services_24_7          0.025864\n",
      "language_match                     0.000000\n",
      "dtype: float64\n",
      "\n",
      "--- Best model for 'Culturally Similar Provider' trained and stored ----------------------------------------------------------------\n",
      "Training model for cultural preference: Culturally Similar Provider; Same Language Provider (3/4)--------------------------------------\n",
      "Learning feature engineering parameters from the training set...\n",
      "training on features: ['years_experience', 'cultural_competency_rating_prov', 'communication_rating', 'race_match', 'ethnicity_match', 'language_match', 'interpreter_services_24_7', 'historical_avg_adherence', 'proximity_score']\n",
      "Training+Validation set size: 15664 samples\n",
      "Test set size: 3916 samples\n",
      "\n",
      "Starting random parameter search ...\n",
      "  > Running trial 50/50...\n",
      "Search complete after 50 trials. Analyzing results...\n",
      "\n",
      "--- Top 5 Hyperparameter Runs (based on lowest validation RMSE) ---\n",
      "                                               params  mean_rmse  mean_mae  \\\n",
      "20  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.229572  0.193376   \n",
      "49  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.229572  0.193376   \n",
      "34  {'n_estimators': 150, 'min_samples_leaf': 4, '...   0.229588  0.193383   \n",
      "26  {'n_estimators': 100, 'min_samples_leaf': 4, '...   0.229621  0.193401   \n",
      "1   {'n_estimators': 200, 'min_samples_leaf': 2, '...   0.229624  0.193384   \n",
      "\n",
      "     mean_r2  \n",
      "20 -0.004371  \n",
      "49 -0.004371  \n",
      "34 -0.004507  \n",
      "26 -0.004799  \n",
      "1  -0.004815  \n",
      "\n",
      "Best parameters found: {'n_estimators': 200, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "\n",
      "--- Final Evaluation on the Held-Out Test Set ---\n",
      "Test set size: 3916 encounters\n",
      "\n",
      "--- Final Model Validation Metrics ---\n",
      "Root Mean Squared Error (RMSE): 0.2287\n",
      "Mean Absolute Error (MAE):     0.1921\n",
      "R-squared (R²):                -0.0032\n",
      "\n",
      "--- Learned Feature Weights for this Segment ---\n",
      "communication_rating               0.211265\n",
      "proximity_score                    0.188908\n",
      "historical_avg_adherence           0.188475\n",
      "cultural_competency_rating_prov    0.184012\n",
      "years_experience                   0.140864\n",
      "ethnicity_match                    0.027258\n",
      "race_match                         0.025675\n",
      "interpreter_services_24_7          0.025289\n",
      "language_match                     0.008254\n",
      "dtype: float64\n",
      "\n",
      "--- Best model for 'Culturally Similar Provider; Same Language Provider' trained and stored ----------------------------------------------------------------\n",
      "Training model for cultural preference: Same Language Provider (4/4)--------------------------------------\n",
      "Learning feature engineering parameters from the training set...\n",
      "training on features: ['years_experience', 'cultural_competency_rating_prov', 'communication_rating', 'race_match', 'ethnicity_match', 'language_match', 'interpreter_services_24_7', 'historical_avg_adherence', 'proximity_score']\n",
      "Training+Validation set size: 19779 samples\n",
      "Test set size: 4945 samples\n",
      "\n",
      "Starting random parameter search ...\n",
      "  > Running trial 50/50...\n",
      "Search complete after 50 trials. Analyzing results...\n",
      "\n",
      "--- Top 5 Hyperparameter Runs (based on lowest validation RMSE) ---\n",
      "                                               params  mean_rmse  mean_mae  \\\n",
      "34  {'n_estimators': 150, 'min_samples_leaf': 4, '...   0.231286  0.194296   \n",
      "20  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.231294  0.194296   \n",
      "49  {'n_estimators': 200, 'min_samples_leaf': 4, '...   0.231294  0.194296   \n",
      "26  {'n_estimators': 100, 'min_samples_leaf': 4, '...   0.231302  0.194293   \n",
      "1   {'n_estimators': 200, 'min_samples_leaf': 2, '...   0.231345  0.194339   \n",
      "\n",
      "     mean_r2  \n",
      "34 -0.003119  \n",
      "20 -0.003193  \n",
      "49 -0.003193  \n",
      "26 -0.003268  \n",
      "1  -0.003625  \n",
      "\n",
      "Best parameters found: {'n_estimators': 150, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "\n",
      "--- Final Evaluation on the Held-Out Test Set ---\n",
      "Test set size: 4945 encounters\n",
      "\n",
      "--- Final Model Validation Metrics ---\n",
      "Root Mean Squared Error (RMSE): 0.2292\n",
      "Mean Absolute Error (MAE):     0.1929\n",
      "R-squared (R²):                -0.0055\n",
      "\n",
      "--- Learned Feature Weights for this Segment ---\n",
      "communication_rating               0.212558\n",
      "historical_avg_adherence           0.194378\n",
      "cultural_competency_rating_prov    0.188044\n",
      "proximity_score                    0.188010\n",
      "years_experience                   0.139023\n",
      "interpreter_services_24_7          0.024821\n",
      "race_match                         0.022109\n",
      "ethnicity_match                    0.019854\n",
      "language_match                     0.011205\n",
      "dtype: float64\n",
      "\n",
      "--- Best model for 'Same Language Provider' trained and stored ----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# A dictionary to store a trained model for each preference type\n",
    "trained_models = {}\n",
    "learned_weights_dict = {}\n",
    "best_hyperparameters = {} \n",
    "test_metrics_dict = {}\n",
    "feature_engineering_params = {} # To store scaling values like min/max dist\n",
    "all_run_logs_dict = {}\n",
    "\n",
    "for i, preference in enumerate(unique_preferences):\n",
    "    print(f\"Training model for cultural preference: {preference} ({i+1}/{len(unique_preferences)})--------------------------------------\")\n",
    "    \n",
    "    # Filter the DataFrame for the current preference\n",
    "    segment_df= master_df[master_df['cultural_preferences'] == preference].copy()\n",
    "\n",
    "    # Check if the segment is large enough to train a model\n",
    "    if len(segment_df) < 100: # You can adjust this threshold\n",
    "        print(f\"Segment is too small to train a reliable model. Skipping.\\n\")\n",
    "        continue\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_segment = segment_df.drop(columns=[target])\n",
    "    y_segment = segment_df[target]\n",
    "\n",
    "    # 1. Split data into a training+validation set (80%) and a final test set (20%)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X_segment, y_segment, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # --- 2. stateful FEATURE ENGINEERING (Applied Separately to Train and Test) ---\n",
    "    \n",
    "    # Learn parameters ONLY from the training set\n",
    "    print(\"Learning feature engineering parameters from the training set...\")\n",
    "    avg_adherence_train = X_train_val['treatment_adherence'].mean()\n",
    "    min_dist_train = X_train_val['distance_km'].min()\n",
    "    max_dist_train = X_train_val['distance_km'].max()\n",
    "\n",
    "    # Store these learned parameters for later use in production/inference\n",
    "    feature_engineering_params[preference] = {\n",
    "        'avg_adherence': avg_adherence_train,\n",
    "        'min_dist': min_dist_train,\n",
    "        'max_dist': max_dist_train\n",
    "    }\n",
    "\n",
    "    # Apply the function to both train and test sets\n",
    "    X_train_val = create_features(X_train_val, avg_adherence_train, min_dist_train, max_dist_train)\n",
    "    X_test = create_features(X_test, avg_adherence_train, min_dist_train, max_dist_train)\n",
    "    \n",
    "    X_train_val=X_train_val[features]\n",
    "    X_test=X_test[features]\n",
    "\n",
    "    print(f\"training on features: {X_train_val.columns.tolist()}\")\n",
    "    print(f\"Training+Validation set size: {X_train_val.shape[0]} samples\")\n",
    "    print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "    # --- Hyperparameter Tuning Section (using the validation data implicitly via CV) ---\n",
    "\n",
    "    print(\"\\nStarting random parameter search ...\")\n",
    "\n",
    "    # 1. Define the hyperparameter grid (as before)\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', 1.0]\n",
    "    }\n",
    "\n",
    "    # 2. Create the ParameterSampler iterator\n",
    "    # This will generate 50 random, unique combinations to test.\n",
    "    n_iterations = 50 \n",
    "    param_sampler = ParameterSampler(\n",
    "        param_grid, \n",
    "        n_iter=n_iterations, \n",
    "        random_state=42)\n",
    "\n",
    "    total_combinations = n_iterations # Calculate total runs\n",
    "\n",
    "    # 3. List to store the results of every single run\n",
    "    all_run_logs = []\n",
    "\n",
    "    # 4. Loop through each parameter combination\n",
    "    for run_num, params in enumerate(param_sampler):\n",
    "        print(f\"  > Running trial {run_num + 1}/{total_combinations}...\", end='\\r')\n",
    "        model = RandomForestRegressor(**params, random_state=42, n_jobs=-1)\n",
    "        \n",
    "        # Define the metrics to calculate during cross-validation\n",
    "        scoring_metrics = {\n",
    "            'neg_mse': 'neg_mean_squared_error',\n",
    "            'mae': 'neg_mean_absolute_error',\n",
    "            'r2': 'r2'\n",
    "        }\n",
    "        \n",
    "        # Perform 5-fold cross-validation, returning the trained estimators\n",
    "        cv_results = cross_validate(\n",
    "            model, X_train_val, y_train_val, cv=5,\n",
    "            scoring=scoring_metrics,\n",
    "            return_estimator=True # CRITICAL: This gives us access to the models\n",
    "        )\n",
    "        \n",
    "        # Calculate mean feature importances across the 5 folds\n",
    "        fold_importances = [est.feature_importances_ for est in cv_results['estimator']]\n",
    "        mean_importances = np.mean(fold_importances, axis=0)\n",
    "        \n",
    "        # Store all the results in our log list\n",
    "        all_run_logs.append({\n",
    "            'params': params,\n",
    "            'mean_rmse': np.sqrt(-np.mean(cv_results['test_neg_mse'])),\n",
    "            'mean_mae': -np.mean(cv_results['test_mae']),\n",
    "            'mean_r2': np.mean(cv_results['test_r2']),\n",
    "            'feature_importances': dict(zip(features, mean_importances))\n",
    "        })\n",
    "    print(f\"\\nSearch complete after {total_combinations} trials. Analyzing results...\")\n",
    "\n",
    "    # 5. Convert logs to a DataFrame for easy analysis\n",
    "    results_df = pd.DataFrame(all_run_logs)\n",
    "    results_df = results_df.sort_values(by='mean_rmse', ascending=True)\n",
    "\n",
    "    print(\"\\n--- Top 5 Hyperparameter Runs (based on lowest validation RMSE) ---\")\n",
    "    print(results_df[['params', 'mean_rmse', 'mean_mae', 'mean_r2']].head())\n",
    "    \n",
    "    # 6. Get the best parameters and train the final model on all training data\n",
    "    best_params = results_df.iloc[0]['params']\n",
    "    print(f\"\\nBest parameters found: {best_params}\")\n",
    "    best_hyperparameters[preference] = best_params\n",
    "    \n",
    "    best_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "    best_model.fit(X_train_val, y_train_val)\n",
    "    all_run_logs_dict[preference] = results_df\n",
    "\n",
    "\n",
    "    # --- Final Testing Section ---\n",
    "\n",
    "    print(\"\\n--- Final Evaluation on the Held-Out Test Set ---\")\n",
    "    print(f\"Test set size: {X_test.shape[0]} encounters\")\n",
    "    \n",
    "    # 6. Make predictions on the unseen test data\n",
    "    final_predictions = best_model.predict(X_test)\n",
    "\n",
    "    # 7. Evaluate the final model's performance\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "    mae = mean_absolute_error(y_test, final_predictions)\n",
    "    r2 = r2_score(y_test, final_predictions)\n",
    "\n",
    "    print(\"\\n--- Final Model Validation Metrics ---\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE):     {mae:.4f}\")\n",
    "    print(f\"R-squared (R²):                {r2:.4f}\")\n",
    "\n",
    "    # store the test run results \n",
    "    # You can store these metrics in a dictionary or DataFrame if needed\n",
    "    test_metrics = {\n",
    "        'preference': preference,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'test_set_size': X_test.shape[0]\n",
    "    }\n",
    "\n",
    "    # 8. Inspect and store the results from the best model\n",
    "    learned_weights = pd.Series(best_model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "    print(\"\\n--- Learned Feature Weights for this Segment ---\")\n",
    "    print(learned_weights)\n",
    "\n",
    "    test_metrics_dict[preference] = test_metrics\n",
    "    trained_models[preference] = best_model\n",
    "    learned_weights_dict[preference] = learned_weights\n",
    "    print(f\"\\n--- Best model for '{preference}' trained and stored ----------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5906cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Generating Final Model Summary Report ---\n",
      "\\nSuccessfully created 'model_summary_report_final.xlsx' with title, summary, and all results on the 'All_run_metrics' sheet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerry\\AppData\\Local\\Temp\\ipykernel_21188\\1696115966.py:45: DeprecationWarning: Call to deprecated function copy (Use copy(obj) or cell.obj = cell.obj + other).\n",
      "  worksheet['A3'].alignment = worksheet['A3'].alignment.copy(wrap_text=True, vertical='top')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl.styles import Font # Import Font for styling\n",
    "\n",
    "# --- Report Generation Section ---\n",
    "# This code should be run AFTER your training loop is complete.\n",
    "\n",
    "print(\"\\\\n--- Generating Final Model Summary Report ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Consolidate the dictionaries into clean DataFrames\n",
    "    metrics_df = pd.DataFrame(test_metrics_dict).T\n",
    "    weights_df = pd.DataFrame(learned_weights_dict).reset_index().rename(columns={'index': 'feature'})\n",
    "    hyperparams_df = pd.DataFrame(best_hyperparameters).reset_index().rename(columns={'index': 'hyperparameter'})\n",
    "\n",
    "    # create a folder 'Summary_reports' if it doesn't exist\n",
    "    if not os.path.exists('Summary_reports'):\n",
    "        os.makedirs('Summary_reports')\n",
    "    \n",
    "\n",
    "    # 2. Use pandas ExcelWriter to create the report\n",
    "    timestamp = pd.Timestamp.now().strftime(\"%m%d_%H%M\")\n",
    "    with pd.ExcelWriter(f'Summary_reports/{Model_code}_report_{timestamp}.xlsx', engine='openpyxl') as writer:\n",
    "        sheet_name = 'Model_Summary'\n",
    "        \n",
    "        # --- NEW: Add Title and Summary at the top of the sheet ---\n",
    "        \n",
    "        # Get the workbook and worksheet objects\n",
    "        workbook  = writer.book\n",
    "        # Create the sheet if it doesn't exist, otherwise get it\n",
    "        if sheet_name not in workbook.sheetnames:\n",
    "            worksheet = workbook.create_sheet(sheet_name)\n",
    "        else:\n",
    "            worksheet = workbook[sheet_name]\n",
    "        writer.sheets[sheet_name] = worksheet\n",
    "\n",
    "        # a) Add Model Name (Title)\n",
    "        \n",
    "        worksheet['A1'] = Model_Name\n",
    "        worksheet['A1'].font = Font(bold=True, size=14)\n",
    "\n",
    "        # b) Add Model Summary\n",
    "        model_summary = Model_Summary\n",
    "        worksheet.merge_cells('A3:J8') # Merge cells for a nice text block\n",
    "        worksheet['A3'] = model_summary\n",
    "        worksheet['A3'].alignment = worksheet['A3'].alignment.copy(wrap_text=True, vertical='top')\n",
    "\n",
    "        # --- Write DataFrames (with updated start rows) ---\n",
    "        \n",
    "        # Define the starting row for the first table, leaving space for the title and summary\n",
    "        current_row = 11 \n",
    "\n",
    "        # a) Write Metrics Table\n",
    "        worksheet.cell(row=current_row, column=1).value = \"Performance Metrics\"\n",
    "        worksheet.cell(row=current_row, column=1).font = Font(bold=True)\n",
    "        metrics_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=True)\n",
    "        current_row += metrics_df.shape[0] + 4 # Update current_row for the next table\n",
    "\n",
    "        # b) Write Weights Table\n",
    "        worksheet.cell(row=current_row, column=1).value = \"Learned Feature Weights\"\n",
    "        worksheet.cell(row=current_row, column=1).font = Font(bold=True)\n",
    "        weights_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False)\n",
    "        current_row += weights_df.shape[0] + 4\n",
    "\n",
    "        # c) Write Hyperparameters Table\n",
    "        worksheet.cell(row=current_row, column=1).value = \"Best Hyperparameters\"\n",
    "        worksheet.cell(row=current_row, column=1).font = Font(bold=True)\n",
    "        hyperparams_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False)\n",
    "\n",
    "        sheet_name = 'All_run_metrics'\n",
    "        # Create the sheet if it doesn't exist, otherwise get it\n",
    "        if sheet_name not in workbook.sheetnames:\n",
    "            worksheet = workbook.create_sheet(sheet_name)\n",
    "        else:\n",
    "            worksheet = workbook[sheet_name]\n",
    "        writer.sheets[sheet_name] = worksheet\n",
    "\n",
    "        # Write all run metrics\n",
    "        for i, (preference, df) in enumerate(all_run_logs_dict.items()):\n",
    "            start_row = i * (df.shape[0] + 4) + 1 # Leave 4 rows between tables\n",
    "            worksheet.cell(row=start_row, column=1).value = f\"All Run Metrics for Preference: {preference}\"\n",
    "            worksheet.cell(row=start_row, column=1).font = Font(bold=True)\n",
    "            df.to_excel(writer, sheet_name=sheet_name, startrow=start_row + 1, index=False)\n",
    "        \n",
    "\n",
    "    print(f\"\\\\nSuccessfully created 'model_summary_report_final.xlsx' with title, summary, and all results on the '{sheet_name}' sheet.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\\\nAn error occurred during report generation: {e}\")\n",
    "    print(\"Please ensure the training loop completed successfully and populated the result dictionaries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a8b98fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file found at 'Model_Artifacts\\RandomForestRegressor_PatientSatisfactionOnly_artifacts.joblib'. Archiving it.\n",
      "Renamed existing file to 'Model_Artifacts\\RandomForestRegressor_PatientSatisfactionOnly_artifacts_20250929_130241.joblib'\n",
      "\\n--- Training artifacts saved successfully to 'Model_Artifacts\\RandomForestRegressor_PatientSatisfactionOnly_artifacts.joblib' ---\n",
      "This file contains:\n",
      "- 4 trained model(s)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import joblib\n",
    "\n",
    "\n",
    "# --- This code runs AFTER your training loop is complete ---\n",
    "\n",
    "# 1. First, get the min and max distance from your full training data\n",
    "min_dist_training = master_df['distance_km'].min()\n",
    "max_dist_training = master_df['distance_km'].max()\n",
    "\n",
    "# 2. Create a dictionary to hold all the objects you need to save\n",
    "artifacts_to_save = {\n",
    "    'models': trained_models,\n",
    "    'feature_engineering_params': feature_engineering_params,\n",
    "    \n",
    "}\n",
    "\n",
    "# 3. Save the dictionary to a single file using joblib\n",
    "file_path = f'{Model_Name}_artifacts.joblib'\n",
    "\n",
    "# Create folder 'Model_Artifacts' if it doesn't exist\n",
    "if not os.path.exists('Model_Artifacts'):\n",
    "    os.makedirs('Model_Artifacts')\n",
    "file_path = os.path.join('Model_Artifacts', file_path)\n",
    "\n",
    "# Check if a file already exists at that path\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Existing file found at '{file_path}'. Archiving it.\")\n",
    "    \n",
    "    # Create a timestamp string (e.g., \"20250929_091303\")\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Split the original file path into its base name and extension\n",
    "    base_name, extension = os.path.splitext(file_path)\n",
    "    \n",
    "    # Create the new name for the *old* file by inserting the timestamp\n",
    "    archive_file_path = f\"{base_name}_{timestamp}{extension}\"\n",
    "    \n",
    "    # Rename the old file\n",
    "    os.rename(file_path, archive_file_path)\n",
    "    print(f\"Renamed existing file to '{archive_file_path}'\")\n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(artifacts_to_save, file_path)\n",
    "\n",
    "print(f\"\\\\n--- Training artifacts saved successfully to '{file_path}' ---\")\n",
    "print(\"This file contains:\")\n",
    "print(f\"- {len(artifacts_to_save['models'])} trained model(s)\")\n",
    "# print(f\"- Training Min Distance: {artifacts_to_save['min_dist']:.2f}\")\n",
    "# print(f\"- Training Max Distance: {artifacts_to_save['max_dist']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f778939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0908fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(learned_weights_dict).reset_index(drop=False).rename(columns={'index': 'feature'})\n",
    "hyperparams_df = pd.DataFrame(best_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0440b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models trained and stored: 4\n",
      "learned_weights_dict keys: dict_keys(['No Specific Preference', 'Culturally Similar Provider', 'Culturally Similar Provider; Same Language Provider', 'Same Language Provider'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total models trained and stored: {len(trained_models)}\")\n",
    "print(f'learned_weights_dict keys: {learned_weights_dict.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdca1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Training Section ---\n",
    "\n",
    "# # 1. Normalize the columns to a 0-1 scale\n",
    "# scaler = MinMaxScaler()\n",
    "# master_df[['satisfaction_norm', 'adherence_norm']] = scaler.fit_transform(\n",
    "#     master_df[['patient_satisfaction', 'treatment_adherence']]\n",
    "# )\n",
    "\n",
    "# # 2. Define weights and create the composite score\n",
    "# adherence_weight = 0.5\n",
    "# satisfaction_weight = 0.5\n",
    "# master_df['success_score'] = (\n",
    "#     master_df['adherence_norm'] * adherence_weight +\n",
    "#     master_df['satisfaction_norm'] * satisfaction_weight\n",
    "# )\n",
    "\n",
    "# # Rename provider competency column to avoid conflict\n",
    "# master_df.rename(columns={'cultural_competency_rating_y': 'cultural_competency_rating_prov'}, inplace=True)\n",
    "\n",
    "# # Define the features to be used by the models\n",
    "# features = [\n",
    "#     'years_experience',\n",
    "#     'cultural_competency_rating_prov',\n",
    "#     'communication_rating',\n",
    "#     'race_match',\n",
    "#     'ethnicity_match',\n",
    "#     'language_match',\n",
    "#     'proximity_score',\n",
    "#     'interpreter_services_24_7'\n",
    "# ]\n",
    "# target = 'success_score'\n",
    "\n",
    "# # --- Segmented Training and Testing ---\n",
    "\n",
    "# # Get the unique preference categories to loop through\n",
    "# unique_preferences = master_df['cultural_preferences'].unique()\n",
    "# print(\"Unique cultural preferences found: \", unique_preferences)\n",
    "\n",
    "# # A dictionary to store a trained model for each preference type\n",
    "# trained_models = {}\n",
    "# learned_weights_dict = {}\n",
    "\n",
    "# i=1\n",
    " \n",
    "# for preference in unique_preferences:\n",
    "#     print(f'preference segment {i} of {len(unique_preferences)}')\n",
    "#     print(f\"Processing Segment: '{preference}' ---\")\n",
    "    \n",
    "#     # Create a subset of the data for the current preference type\n",
    "#     segment_df = master_df[master_df['cultural_preferences'] == preference].copy()\n",
    "    \n",
    "#     # Check if the segment is large enough to train a model\n",
    "#     if len(segment_df) < 50: # You can adjust this threshold\n",
    "#         print(f\"Segment is too small to train a reliable model. Skipping.\\n\")\n",
    "#         continue\n",
    "\n",
    "#     # --- Training Section for the Segment ---\n",
    "    \n",
    "#     X_segment = segment_df[features]\n",
    "#     y_segment = segment_df[target]\n",
    "\n",
    "#     # 1. Split the segment's data into a training set (80%) and a testing set (20%)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_segment, y_segment, test_size=0.2, random_state=42)\n",
    "\n",
    "#     print(f\"Training set size: {X_train.shape[0]} encounters\")\n",
    "#     print(f\"Testing set size: {X_test.shape[0]} encounters\")\n",
    "\n",
    "#     # 2. Initialize and train a new Random Forest model for this segment\n",
    "#     model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # --- Testing Section for the Segment ---\n",
    "\n",
    "#     # 3. Make predictions on the unseen test data for this segment\n",
    "#     predictions = model.predict(X_test)\n",
    "\n",
    "#     # 4. Evaluate the model's performance\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "#     mae = mean_absolute_error(y_test, predictions)\n",
    "#     r2 = r2_score(y_test, predictions)\n",
    "\n",
    "#     print(\"\\n--- Model Validation Metrics ---\")\n",
    "#     print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "#     print(f\"Mean Absolute Error (MAE):     {mae:.4f}\")\n",
    "#     print(f\"R-squared (R²):                {r2:.4f}\")\n",
    "\n",
    "#     # 5. Inspect the 'Learned Weights' (Feature Importances) for this specific model\n",
    "#     learned_weights = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "#     print(\"\\n--- Learned Feature Weights for this Segment ---\")\n",
    "#     print(learned_weights)\n",
    "    \n",
    "#     # 6. Store the trained model\n",
    "#     trained_models[preference] = model\n",
    "#     learned_weights_dict[preference] = learned_weights\n",
    "#     print(f\"--- Model for '{preference}' trained and stored ---\\n\")\n",
    "#     i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bb16a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dictionary to dataframe\n",
    "learned_weights_df = pd.DataFrame(learned_weights)\n",
    "learned_weights_df.index.name = 'cultural_preferences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e712f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference: No Specific Preference\n",
      "[0.30228134356710645, 0.2587297265880648, 0.22706208377863857, 0.15078194310374118, 0.023369602943468116, 0.019298029084975906, 0.018477270934005034, 0.0]\n",
      "Preference: Culturally Similar Provider\n",
      "[0.27944612196356666, 0.24964349079718437, 0.23633818785769584, 0.1643383978767721, 0.024942262879027864, 0.023974037786980082, 0.021317500838773054, 0.0]\n",
      "Preference: Culturally Similar Provider; Same Language Provider\n",
      "[0.8291991791822869, 0.0616554138482501, 0.03980004991148326, 0.03006834916789543, 0.02568487766919535, 0.00490442265660199, 0.0045826925833540415, 0.0041050149809329]\n",
      "Preference: Same Language Provider\n",
      "[0.8799899038622955, 0.04331520487270709, 0.02771284454615456, 0.024068233884902663, 0.017199764006714646, 0.0028091691752090285, 0.002541019572876003, 0.002363860079140613]\n"
     ]
    }
   ],
   "source": [
    "for key in learned_weights_dict.keys():\n",
    "    print(f\"Preference: {key}\")\n",
    "    print(learned_weights_dict[key].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a75a37",
   "metadata": {},
   "source": [
    "# Convert learned_weights dictionary to a DataFrame\n",
    "learned_weights_df = pd.DataFrame(learned_weights)\n",
    "learned_weights_df.index.name = 'feature'\n",
    "display(learned_weights_df)mendations for a new patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "302a7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(patient_id, required_specialty, \n",
    "                        # DataFrames\n",
    "                        all_providers_df, \n",
    "                        all_patients_df, \n",
    "                        all_hospitals_df,\n",
    "                        # Trained Models & Scaling Data\n",
    "                        models_dict,\n",
    "                        training_min_dist, \n",
    "                        training_max_dist):\n",
    "    \"\"\"\n",
    "    Generates ranked doctor recommendations using the segmented model strategy.\n",
    "    \n",
    "    Args:\n",
    "        patient_id (int): The ID of the patient seeking a recommendation.\n",
    "        required_specialty (str): The medical specialty required.\n",
    "        all_providers_df (pd.DataFrame): The full provider dataframe.\n",
    "        all_patients_df (pd.DataFrame): The full patient dataframe.\n",
    "        all_hospitals_df (pd.DataFrame): The full hospital dataframe.\n",
    "        models_dict (dict): The dictionary of trained models for each preference segment.\n",
    "        training_min_dist (float): The minimum distance calculated from the full training set.\n",
    "        training_max_dist (float): The maximum distance calculated from the full training set.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A ranked dataframe of recommended providers.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Recommendation Phase for Patient ID: {patient_id} ---\")\n",
    "    \n",
    "    # --- Step 1: Patient Lookup & Model Routing ---\n",
    "    patient_info = all_patients_df[all_patients_df['patient_id'] == patient_id]\n",
    "    if patient_info.empty:\n",
    "        return \"Error: Patient ID not found.\"\n",
    "        \n",
    "    preference = patient_info['cultural_preferences'].iloc[0]\n",
    "    model_to_use = None\n",
    "    model_name = \"\"\n",
    "\n",
    "    # Determine which trained model to use based on the patient's preference\n",
    "    if preference == 'Culturally Similar Provider; Same Language Provider':\n",
    "        model_name = 'Culturally Similar Provider; Same Language Provider' # Match the exact key from training\n",
    "    elif preference == 'Culturally Similar Provider':\n",
    "        model_name = 'Culturally Similar Provider'\n",
    "    elif preference == 'Same Language Provider':\n",
    "        model_name = 'Same Language Provider'\n",
    "    else: # Fallback for any other preferences, like just \"Same Language Provider\"\n",
    "        model_name = 'No Specific Preference'\n",
    "\n",
    "    model_to_use = models_dict.get(model_name)\n",
    "    print(f\"Patient preference: '{preference}'. Routing to '{model_name}' model.\")\n",
    "        \n",
    "    if not model_to_use:\n",
    "        return f\"Error: Model for preference group '{model_name}' was not trained (likely due to small size).\"\n",
    "\n",
    "\n",
    "    # --- Step 2: Candidate Generation (Hard Filters) ---\n",
    "    candidate_providers_accepting_new = all_providers_df[all_providers_df['accepts_new_patients'] == True]\n",
    "    previous_provider=encounter_df[encounter_df['patient_id']==patient_id]['provider_id'].unique()\n",
    "    candidate_providers_not_accepting_new = all_providers_df[\n",
    "        (all_providers_df['accepts_new_patients'] == False) &\n",
    "        (all_providers_df['provider_id'].isin(previous_provider))\n",
    "    ]\n",
    "    \n",
    "    candidate_providers_all=pd.concat([candidate_providers_accepting_new,candidate_providers_not_accepting_new])\n",
    "\n",
    "    candidate_providers = candidate_providers_all[\n",
    "        (candidate_providers_all['specialty'] == required_specialty)         \n",
    "    ].copy()\n",
    "    if candidate_providers.empty:\n",
    "        print(f\"No providers found for specialty '{required_specialty}' \")\n",
    "        candidate_providers = candidate_providers_all\n",
    "\n",
    "    # --- Step 3: Feature Engineering for Inference ---\n",
    "    # Merge all necessary info for the patient and candidate providers\n",
    "    inference_df = candidate_providers.assign(key=1).merge(patient_info.assign(key=1), on='key').drop('key', axis=1)\n",
    "    inference_df = pd.merge(inference_df, all_hospitals_df, left_on='hospital_affiliation', right_on='hospital_id', how='left')\n",
    "\n",
    "    print(f'inference_df columns: {inference_df.columns.tolist()}')\n",
    "\n",
    "    # Re-create the exact same features used in training\n",
    "    inference_df.rename(columns={'cultural_competency_rating_y': 'cultural_competency_rating_prov'}, inplace=True)\n",
    "    inference_df['race_match'] = (inference_df['race'] == inference_df['provider_race']).astype(int)\n",
    "    inference_df['ethnicity_match'] = (inference_df['ethnicity'] == inference_df['provider_ethnicity']).astype(int)\n",
    "\n",
    "    # create language match if preferred_provider_language in languages_spoken (semicolon-separated string)\n",
    "    def language_match_func(row):\n",
    "        if pd.isna(row['languages_spoken']) or pd.isna(row['preferred_provider_language']):\n",
    "            return 0\n",
    "        spoken = [lang.strip() for lang in str(row['languages_spoken']).split(';')]\n",
    "        return 1 if row['preferred_provider_language'] in spoken else 0\n",
    "\n",
    "    inference_df['language_match'] = inference_df.apply(language_match_func, axis=1)\n",
    "\n",
    "    # Geographic Feature - CRITICAL: Use the same scaling as the training data\n",
    "    dist = pgeocode.GeoDistance('US')\n",
    "    inference_df['distance_km'] = dist.query_postal_code(\n",
    "        inference_df['zip_code_x'].astype(str).tolist(), \n",
    "        inference_df['zip_code_y'].astype(str).tolist()\n",
    "    )\n",
    "    # Impute missing distances using the same logic (specialty mean, then global mean)\n",
    "    mean_dist_by_specialty = inference_df.groupby('specialty')['distance_km'].transform('mean')\n",
    "    inference_df['distance_km'].fillna(mean_dist_by_specialty, inplace=True)\n",
    "    inference_df['distance_km'].fillna(training_max_dist / 2, inplace=True) # Fallback with a reasonable value\n",
    "\n",
    "    inference_df['proximity_score'] = 1 - (\n",
    "        (inference_df['distance_km'] - training_min_dist) / (training_max_dist - training_min_dist)\n",
    "    )\n",
    "    # Clip scores to be between 0 and 1, in case a new distance is outside the training range\n",
    "    inference_df['proximity_score'] = inference_df['proximity_score'].clip(0, 1)\n",
    "\n",
    "    inference_df['cultural_competency_rating_prov'] = inference_df['cultural_competency_rating']\n",
    "    # --- Step 4: Predict Scores ---\n",
    "    # Ensure the feature list matches the one used for training\n",
    "    features = [\n",
    "        'years_experience', 'cultural_competency_rating_prov', 'communication_rating',\n",
    "        'race_match', 'ethnicity_match', 'language_match', 'proximity_score', \n",
    "        'interpreter_services_24_7'\n",
    "    ]\n",
    "    X_inference = inference_df[features]\n",
    "    predicted_scores = model_to_use.predict(X_inference)\n",
    "    inference_df['predicted_success_score'] = predicted_scores\n",
    "\n",
    "    # --- Step 5: Rank and Return ---\n",
    "    recommendations = inference_df.sort_values(by='predicted_success_score', ascending=False)\n",
    "\n",
    "    print(\"--- Recommendations Generated ---\")\n",
    "   # print(\"--- Recommendations Generated ---\")\n",
    "    return recommendations[['provider_id', 'first_name_x', 'last_name_x', 'specialty', 'hospital_name','distance_km', 'predicted_success_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbcf034",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Example Usage ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# First, get the min and max distance from your *full* training data to pass to the function\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m min_dist_training \u001b[38;5;241m=\u001b[39m \u001b[43mmaster_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_km\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m      4\u001b[0m max_dist_training \u001b[38;5;241m=\u001b[39m master_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_km\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Replace with a real patient_id and specialty from your data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'master_df' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "# First, get the min and max distance from your *full* training data to pass to the function\n",
    "min_dist_training = master_df['distance_km'].min()\n",
    "max_dist_training = master_df['distance_km'].max()\n",
    "\n",
    "# Replace with a real patient_id and specialty from your data\n",
    "example_patient_id = 'PAT_046599' # Replace with a valid ID\n",
    "example_specialty = 'Cardiology' # Replace with a valid specialty\n",
    "\n",
    "# Ensure that there are models trained before running this\n",
    "if trained_models:\n",
    "    final_recommendations = get_recommendations(\n",
    "        patient_id=example_patient_id,\n",
    "        required_specialty=example_specialty,\n",
    "        all_providers_df=provider_df,\n",
    "        all_patients_df=patient_df,\n",
    "        all_hospitals_df=hospital_df,\n",
    "        models_dict=trained_models,\n",
    "        training_min_dist=min_dist_training,\n",
    "        training_max_dist=max_dist_training\n",
    "    )\n",
    "    display(final_recommendations.head(5))\n",
    "    \n",
    "else:\n",
    "    print(\"No models were trained, cannot generate recommendations.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243aa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c075483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fb2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a89de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env2709_Capstone_py_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
